{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0323c714",
   "metadata": {},
   "source": [
    "## Module_1 Homework "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "476a5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c44a8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import elastic search\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea589b3",
   "metadata": {},
   "source": [
    "**question 1:** What's the version.build_hash value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7577c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f05b9372a9a4a470db3b52817899b99a76ee73'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_search = Elasticsearch(\"http://localhost:9200\")\n",
    "e_search.info()[\"version\"][\"build_hash\"] #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce96a53",
   "metadata": {},
   "source": [
    "**Question 2:** Which function do you use for adding your data to elastic?\n",
    "\n",
    "insert\n",
    "\n",
    "index\n",
    "\n",
    "put\n",
    "\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d22be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question_2 = \"index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4300d",
   "metadata": {},
   "source": [
    "### indexing the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90206d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "e_search.indices.create(index=index_name, body=index)\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    e_search.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d59c70",
   "metadata": {},
   "source": [
    "### implement elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "661aa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "De_q = \"How do I execute a command in a running docker container?\"\n",
    "De_course = \"data-engineering-zoomcamp\"\n",
    "De_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b061321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: Module 1: Docker and Terraform\n",
      "Question: PGCLI - running in a Docker container\n",
      "Answer: In case running pgcli  locally causes issues or you do not w...\n",
      "\n",
      "Section: Module 1: Docker and Terraform\n",
      "Question: PGCLI - running in a Docker container\n",
      "Answer: In case running pgcli  locally causes issues or you do not w...\n",
      "\n",
      "Section: Module 1: Docker and Terraform\n",
      "Question: PGCLI - running in a Docker container\n",
      "Answer: In case running pgcli  locally causes issues or you do not w...\n",
      "\n",
      "Section: Module 6: streaming with kafka\n",
      "Question: How do I check compatibility of local and container Spark versions?\n",
      "Answer: You can check the version of your local spark using spark-su...\n",
      "\n",
      "Section: Module 6: streaming with kafka\n",
      "Question: How do I check compatibility of local and container Spark versions?\n",
      "Answer: You can check the version of your local spark using spark-su...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_query = {\n",
    "    \"size\": De_size, #size of search output\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": De_q, #query\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": De_course #filter\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "De_response = e_search.search(index=index_name, body=search_query)\n",
    "for res in De_response[\"hits\"][\"hits\"]:\n",
    "    print(f\"Section: {res['_source']['section']}\")\n",
    "    print(f\"Question: {res['_source']['question']}\")\n",
    "    print(f\"Answer: {res['_source']['text'][:60]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158dc177",
   "metadata": {},
   "source": [
    "**Question 3:** What's the score for the top ranking result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3dfcf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.70745"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find top record score\n",
    "top_record_score =De_response[\"hits\"][\"hits\"][0][\"_score\"]\n",
    "\n",
    "top_record_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135605ea",
   "metadata": {},
   "source": [
    "### Filtring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30910cf",
   "metadata": {},
   "source": [
    "limit the questions to machine-learning-zoomcamp and return 3 results. \n",
    "\n",
    "**Question 4:** What's the 3rd question returned by the search engine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59f461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_q = \"How do I execute a command in a running docker container?\"\n",
    "ml_course = \"machine-learning-zoomcamp\"\n",
    "ml_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27bc00b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#implement elastic search function\n",
    "def elastic_search(query, size, course):\n",
    "    search_query = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^4\", \"text\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": course\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = e_search.search(index=index_name, body=search_query)\n",
    "    response['hits']['hits']\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fef56686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How do I debug a docker container?\n"
     ]
    }
   ],
   "source": [
    "ml_response = elastic_search(ml_q, ml_size, ml_course)\n",
    "third_question =  ml_response[-1]\n",
    "#print(f\"Section: {third_question['section']}\")\n",
    "print(f\"Question: {third_question['question']}\")\n",
    "#print(f\"Answer: {third_question['text'][:60]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04b092",
   "metadata": {},
   "source": [
    "### Building a prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31fb0f",
   "metadata": {},
   "source": [
    "**Question 5:** What's the length of the resulting prompt? (use the len function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "457bc248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1497"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#def build_prompt(query):\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "context = \"\"\n",
    "results = elastic_search(ml_q, ml_size, ml_course)\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "\n",
    "prompt = prompt_template.format(question=ml_q, context=context).strip()\n",
    "len(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061f38f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 332\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "\n",
    "tokens = tokenizer.encode(prompt)\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "\n",
    "print(f\"Number of tokens: {num_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad06fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
